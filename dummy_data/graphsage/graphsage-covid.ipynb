{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from encoders import Encoder\n",
    "from aggregators import MeanAggregator\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes,num_nodes,num_fts,adj_lists,hidden_dim=256,use_gpu=False):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.features = nn.Embedding(num_nodes, num_fts)\n",
    "        # features.cuda()\n",
    "\n",
    "        self.agg1 = MeanAggregator(self.features, cuda=True)\n",
    "        self.enc1 = Encoder(self.features, num_fts, 512, adj_lists, self.agg1, gcn=True, cuda=use_gpu)\n",
    "        self.agg2 = MeanAggregator(lambda nodes : self.enc1(nodes).t(), cuda=use_gpu)\n",
    "        self.enc2 = Encoder(lambda nodes : self.enc1(nodes).t(), self.enc1.embed_dim, 512, adj_lists, self.agg2,\n",
    "                base_model=self.enc1, gcn=True, cuda=use_gpu)\n",
    "        self.enc1.num_samples = 5\n",
    "        self.enc2.num_samples = 5\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.enc2.embed_dim*2,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc6 = nn.Linear(hidden_dim,num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, nodes_u,nodes_v):\n",
    "        embeds_u = self.enc2(nodes_u).t()\n",
    "        embeds_v = self.enc2(nodes_v).t()\n",
    "        \n",
    "        embeds = torch.cat((embeds_u,embeds_v),1)\n",
    "        \n",
    "        embeds = self.fc1(embeds)\n",
    "        embeds = self.fc2(F.relu(embeds))\n",
    "        embeds = self.fc3(F.relu(embeds))\n",
    "        embeds = self.fc4(F.relu(embeds))\n",
    "        embeds = self.fc5(F.relu(embeds))\n",
    "        scores = self.fc6(F.relu(embeds))\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_u = np.load(\"train_pos_u.npy\")\n",
    "train_pos_v = np.load(\"train_pos_v.npy\")\n",
    "train_neg_u = np.load(\"train_neg_u.npy\")\n",
    "train_neg_v = np.load(\"train_neg_v.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = pd.DataFrame()\n",
    "train_graph[\"src\"] = train_pos_u\n",
    "train_graph[\"dst\"] = train_pos_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_main = nx.from_pandas_edgelist(train_graph, source='src', target='dst') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_u = np.load(\"test_pos_u.npy\")\n",
    "test_pos_v = np.load(\"test_pos_v.npy\")\n",
    "test_neg_u = np.load(\"test_neg_u.npy\")\n",
    "test_neg_v = np.load(\"test_neg_v.npy\")\n",
    "train_pos_df = pd.DataFrame()\n",
    "train_pos_df[\"src\"] = train_pos_u\n",
    "train_pos_df[\"dst\"] = train_pos_v\n",
    "train_pos_df[\"labels\"] = [1]*train_pos_u.shape[0]\n",
    "train_neg_df = pd.DataFrame()\n",
    "train_neg_df[\"src\"] = train_neg_u\n",
    "train_neg_df[\"dst\"] = train_neg_v\n",
    "train_neg_df[\"labels\"] = [0]*train_neg_u.shape[0]\n",
    "train_df = train_pos_df.append(train_neg_df)\n",
    "test_pos_df = pd.DataFrame()\n",
    "test_pos_df[\"src\"] = test_pos_u\n",
    "test_pos_df[\"dst\"] = test_pos_v\n",
    "test_pos_df[\"labels\"] = [1]*test_pos_u.shape[0]\n",
    "test_neg_df = pd.DataFrame()\n",
    "test_neg_df[\"src\"] = test_neg_u\n",
    "test_neg_df[\"dst\"] = test_neg_v\n",
    "test_neg_df[\"labels\"] = [0]*test_neg_u.shape[0]\n",
    "test_df = test_pos_df.append(test_neg_df)\n",
    "test_df = test_df.sample(frac=1,replace=False)\n",
    "train_df = train_df.sample(frac=1,replace=False)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(set)\n",
    "for s, nbrs in G_main.adjacency():\n",
    "    d[s] = set()\n",
    "    for t, data in nbrs.items():\n",
    "            d[s].add(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = G_main.number_of_nodes()\n",
    "num_classes=1\n",
    "num_ftrs = 2048\n",
    "hidden_dim = 512\n",
    "num_epochs =100\n",
    "bsz = train_df.shape[0]\n",
    "bs =4096\n",
    "use_gpu=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    graphsage.cuda()\n",
    "\n",
    "model= SupervisedGraphSage(num_classes,num_nodes,num_ftrs,d,hidden_dim,use_gpu).to(device)\n",
    "rand_indices = np.random.permutation(num_nodes)\n",
    "\n",
    "train = list(rand_indices)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "scheduler= OneCycleLR(optimizer, max_lr=learning_rate, \n",
    "                                            steps_per_epoch=int(bsz/bs),\n",
    "                                            epochs=num_epochs,final_div_factor = 1,\n",
    "                                            anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bsz = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strating epoch : 1\n",
      "Train Loss:  0.6918777615190989\n",
      "Train AUC:  0.6293569107762017\n",
      "test Loss:  0.6875803917646408\n",
      "test AUC:  0.7612928764670616\n",
      "Waiting for  0 best AUC is  0.7612928764670616\n",
      "strating epoch : 2\n",
      "Train Loss:  0.4823405602610255\n",
      "Train AUC:  0.8880271208935899\n",
      "test Loss:  0.5954254865646362\n",
      "test AUC:  0.8016492607172923\n",
      "Waiting for  0 best AUC is  0.8016492607172923\n",
      "strating epoch : 3\n",
      "Train Loss:  0.3116117934864688\n",
      "Train AUC:  0.9420546044343987\n",
      "test Loss:  0.6457246690988541\n",
      "test AUC:  0.8128090130630261\n",
      "Waiting for  0 best AUC is  0.8128090130630261\n",
      "strating epoch : 4\n",
      "Train Loss:  0.27739345560590906\n",
      "Train AUC:  0.9531424963724657\n",
      "test Loss:  0.6425265446305275\n",
      "test AUC:  0.8338793685947696\n",
      "Waiting for  0 best AUC is  0.8338793685947696\n",
      "strating epoch : 5\n",
      "Train Loss:  0.24493296067398715\n",
      "Train AUC:  0.9633031520176325\n",
      "test Loss:  0.5437791123986244\n",
      "test AUC:  0.8674367184010807\n",
      "Waiting for  0 best AUC is  0.8674367184010807\n",
      "strating epoch : 6\n",
      "Train Loss:  0.23280211582959418\n",
      "Train AUC:  0.9669393843726946\n",
      "test Loss:  0.6308283135294914\n",
      "test AUC:  0.8634796099328624\n",
      "Waiting for  1 best AUC is  0.8674367184010807\n",
      "strating epoch : 7\n",
      "Train Loss:  0.21014618604298096\n",
      "Train AUC:  0.9731374352644588\n",
      "test Loss:  0.5762638002634048\n",
      "test AUC:  0.8647784037681467\n",
      "Waiting for  2 best AUC is  0.8674367184010807\n",
      "strating epoch : 8\n",
      "Train Loss:  0.19673624796321593\n",
      "Train AUC:  0.9763368303992963\n",
      "test Loss:  0.5669044926762581\n",
      "test AUC:  0.8724523022794588\n",
      "Waiting for  0 best AUC is  0.8724523022794588\n",
      "strating epoch : 9\n",
      "Train Loss:  0.20332484791077762\n",
      "Train AUC:  0.97471241016859\n",
      "test Loss:  0.5872578546404839\n",
      "test AUC:  0.8728075814090672\n",
      "Waiting for  0 best AUC is  0.8728075814090672\n",
      "strating epoch : 10\n",
      "Train Loss:  0.20017651369772763\n",
      "Train AUC:  0.9754015561304337\n",
      "test Loss:  0.653530016541481\n",
      "test AUC:  0.8673206249404695\n",
      "Waiting for  1 best AUC is  0.8728075814090672\n",
      "strating epoch : 11\n",
      "Train Loss:  0.19113652605608286\n",
      "Train AUC:  0.9775736449814958\n",
      "test Loss:  0.647603303194046\n",
      "test AUC:  0.8721762954831916\n",
      "Waiting for  2 best AUC is  0.8728075814090672\n",
      "strating epoch : 12\n",
      "Train Loss:  0.2006429979600102\n",
      "Train AUC:  0.9752533875470137\n",
      "test Loss:  0.6565316691994667\n",
      "test AUC:  0.8576279677779899\n",
      "Waiting for  3 best AUC is  0.8728075814090672\n",
      "strating epoch : 13\n",
      "Train Loss:  0.19801037462360888\n",
      "Train AUC:  0.9758951616324106\n",
      "test Loss:  0.5114541202783585\n",
      "test AUC:  0.8722172675531628\n",
      "Waiting for  4 best AUC is  0.8728075814090672\n",
      "strating epoch : 14\n",
      "Train Loss:  0.18896006532462248\n",
      "Train AUC:  0.9780905479554388\n",
      "test Loss:  0.5771926566958427\n",
      "test AUC:  0.8660798020063616\n",
      "Waiting for  5 best AUC is  0.8728075814090672\n",
      "strating epoch : 15\n",
      "Train Loss:  0.19949888734214277\n",
      "Train AUC:  0.975499855281285\n",
      "test Loss:  0.6360894963145256\n",
      "test AUC:  0.8649752524428476\n",
      "Waiting for  6 best AUC is  0.8728075814090672\n",
      "strating epoch : 16\n",
      "Train Loss:  0.18776396186236877\n",
      "Train AUC:  0.9783292534446739\n",
      "test Loss:  0.6022844612598419\n",
      "test AUC:  0.8725949864880356\n",
      "Waiting for  7 best AUC is  0.8728075814090672\n",
      "strating epoch : 17\n",
      "Train Loss:  0.1982214075614171\n",
      "Train AUC:  0.9758203051975154\n",
      "test Loss:  0.5535648167133331\n",
      "test AUC:  0.8664890471357312\n",
      "Waiting for  8 best AUC is  0.8728075814090672\n",
      "strating epoch : 18\n",
      "Train Loss:  0.19694124736699714\n",
      "Train AUC:  0.9761089918380893\n",
      "test Loss:  0.7997800037264824\n",
      "test AUC:  0.8628321639770131\n",
      "Waiting for  9 best AUC is  0.8728075814090672\n",
      "strating epoch : 19\n",
      "Train Loss:  0.19779168248894702\n",
      "Train AUC:  0.9760932284721353\n",
      "test Loss:  0.5322699658572674\n",
      "test AUC:  0.8744980355050482\n",
      "Waiting for  0 best AUC is  0.8744980355050482\n",
      "strating epoch : 20\n",
      "Train Loss:  0.1914462140166616\n",
      "Train AUC:  0.9774799901480982\n",
      "test Loss:  0.5372981503605843\n",
      "test AUC:  0.8676668626166257\n",
      "Waiting for  1 best AUC is  0.8744980355050482\n",
      "strating epoch : 21\n",
      "Train Loss:  0.197570545486657\n",
      "Train AUC:  0.9759759477029829\n",
      "test Loss:  0.7010268345475197\n",
      "test AUC:  0.8717400065034058\n",
      "Waiting for  2 best AUC is  0.8744980355050482\n",
      "strating epoch : 22\n",
      "Train Loss:  0.1988287160554564\n",
      "Train AUC:  0.9757944607391462\n",
      "test Loss:  0.7287797927856445\n",
      "test AUC:  0.8619061966935264\n",
      "Waiting for  3 best AUC is  0.8744980355050482\n",
      "strating epoch : 23\n",
      "Train Loss:  0.1935419235602919\n",
      "Train AUC:  0.9770548682595158\n",
      "test Loss:  0.5197301208972931\n",
      "test AUC:  0.8668424876429974\n",
      "Waiting for  4 best AUC is  0.8744980355050482\n",
      "strating epoch : 24\n",
      "Train Loss:  0.20475453066538615\n",
      "Train AUC:  0.9739952803085454\n",
      "test Loss:  0.5299651697278023\n",
      "test AUC:  0.8739724947040561\n",
      "Waiting for  5 best AUC is  0.8744980355050482\n",
      "strating epoch : 25\n",
      "Train Loss:  0.20132826089140882\n",
      "Train AUC:  0.9749674108516084\n",
      "test Loss:  0.6095444783568382\n",
      "test AUC:  0.8568875440758218\n",
      "Waiting for  6 best AUC is  0.8744980355050482\n",
      "strating epoch : 26\n",
      "Train Loss:  0.19297262218343206\n",
      "Train AUC:  0.9768416536234046\n",
      "test Loss:  0.5082097537815571\n",
      "test AUC:  0.8605528564379858\n",
      "Waiting for  7 best AUC is  0.8744980355050482\n",
      "strating epoch : 27\n",
      "Train Loss:  0.19427069626658797\n",
      "Train AUC:  0.976763800104129\n",
      "test Loss:  0.6177912652492523\n",
      "test AUC:  0.8764345354658118\n",
      "Waiting for  0 best AUC is  0.8764345354658118\n",
      "strating epoch : 28\n",
      "Train Loss:  0.19398736271513514\n",
      "Train AUC:  0.9766045602787673\n",
      "test Loss:  0.5403524301946163\n",
      "test AUC:  0.8782141458944657\n",
      "Waiting for  0 best AUC is  0.8782141458944657\n",
      "strating epoch : 29\n",
      "Train Loss:  0.18341701756040735\n",
      "Train AUC:  0.9792164167734105\n",
      "test Loss:  0.7114998251199722\n",
      "test AUC:  0.8711225196067167\n",
      "Waiting for  1 best AUC is  0.8782141458944657\n",
      "strating epoch : 30\n",
      "Train Loss:  0.19163503327283515\n",
      "Train AUC:  0.9773462348874461\n",
      "test Loss:  0.6323810145258904\n",
      "test AUC:  0.8714145291577269\n",
      "Waiting for  2 best AUC is  0.8782141458944657\n",
      "strating epoch : 31\n",
      "Train Loss:  0.19720505572945238\n",
      "Train AUC:  0.9759344728140047\n",
      "test Loss:  0.7201373502612114\n",
      "test AUC:  0.8705387401621909\n",
      "Waiting for  3 best AUC is  0.8782141458944657\n",
      "strating epoch : 32\n",
      "Train Loss:  0.16740571895995773\n",
      "Train AUC:  0.9826493118643006\n",
      "test Loss:  0.6313788965344429\n",
      "test AUC:  0.8838932440147825\n",
      "Waiting for  0 best AUC is  0.8838932440147825\n",
      "strating epoch : 33\n",
      "Train Loss:  0.19158160937837806\n",
      "Train AUC:  0.9771157274201537\n",
      "test Loss:  0.5075269229710102\n",
      "test AUC:  0.8757616464967175\n",
      "Waiting for  1 best AUC is  0.8838932440147825\n",
      "strating epoch : 34\n",
      "Train Loss:  0.17188412669193315\n",
      "Train AUC:  0.9816910062907761\n",
      "test Loss:  0.6046812385320663\n",
      "test AUC:  0.8749559273611914\n",
      "Waiting for  2 best AUC is  0.8838932440147825\n",
      "strating epoch : 35\n",
      "Train Loss:  0.17926459840263229\n",
      "Train AUC:  0.980068269435574\n",
      "test Loss:  0.4854930080473423\n",
      "test AUC:  0.8781306982782091\n",
      "Waiting for  3 best AUC is  0.8838932440147825\n",
      "strating epoch : 36\n",
      "Train Loss:  0.16424869611320725\n",
      "Train AUC:  0.9833160607622145\n",
      "test Loss:  0.6774347126483917\n",
      "test AUC:  0.8827110472953131\n",
      "Waiting for  4 best AUC is  0.8838932440147825\n",
      "strating epoch : 37\n",
      "Train Loss:  0.18546662309083595\n",
      "Train AUC:  0.9785077664174696\n",
      "test Loss:  0.5644789338111877\n",
      "test AUC:  0.8808067812675853\n",
      "Waiting for  5 best AUC is  0.8838932440147825\n",
      "strating epoch : 38\n",
      "Train Loss:  0.16042736567646623\n",
      "Train AUC:  0.9839539795264952\n",
      "test Loss:  0.5277420878410339\n",
      "test AUC:  0.8824925470638265\n",
      "Waiting for  6 best AUC is  0.8838932440147825\n",
      "strating epoch : 39\n",
      "Train Loss:  0.17215254112898584\n",
      "Train AUC:  0.9816763359550978\n",
      "test Loss:  0.7520246133208275\n",
      "test AUC:  0.8808772218477824\n",
      "Waiting for  7 best AUC is  0.8838932440147825\n",
      "strating epoch : 40\n",
      "Train Loss:  0.1660694400948214\n",
      "Train AUC:  0.9828620681153362\n",
      "test Loss:  0.5358911752700806\n",
      "test AUC:  0.8807798385226746\n",
      "Waiting for  8 best AUC is  0.8838932440147825\n",
      "strating epoch : 41\n",
      "Train Loss:  0.16775549409619298\n",
      "Train AUC:  0.9825138077109427\n",
      "test Loss:  0.6427757143974304\n",
      "test AUC:  0.8794446392160875\n",
      "Waiting for  9 best AUC is  0.8838932440147825\n",
      "strating epoch : 42\n",
      "Train Loss:  0.158774156886411\n",
      "Train AUC:  0.9843345405630235\n",
      "test Loss:  0.6125922501087189\n",
      "test AUC:  0.8809506731252564\n",
      "Waiting for  10 best AUC is  0.8838932440147825\n",
      "strating epoch : 43\n",
      "Train Loss:  0.15629108681018095\n",
      "Train AUC:  0.9848312213968604\n",
      "test Loss:  0.5827069580554962\n",
      "test AUC:  0.8833810996932788\n",
      "Waiting for  11 best AUC is  0.8838932440147825\n",
      "strating epoch : 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.15599570665732923\n",
      "Train AUC:  0.9848154821468484\n",
      "test Loss:  0.5831589847803116\n",
      "test AUC:  0.8866270807157306\n",
      "Waiting for  0 best AUC is  0.8866270807157306\n",
      "strating epoch : 45\n",
      "Train Loss:  0.1515853146472609\n",
      "Train AUC:  0.985643866397619\n",
      "test Loss:  0.5933141484856606\n",
      "test AUC:  0.8855983059839945\n",
      "Waiting for  1 best AUC is  0.8866270807157306\n",
      "strating epoch : 46\n",
      "Train Loss:  0.15684825684650835\n",
      "Train AUC:  0.9846145374124238\n",
      "test Loss:  0.6222728416323662\n",
      "test AUC:  0.8813046903083692\n",
      "Waiting for  2 best AUC is  0.8866270807157306\n",
      "strating epoch : 47\n",
      "Train Loss:  0.14855189962559437\n",
      "Train AUC:  0.9861734182433025\n",
      "test Loss:  0.6753022074699402\n",
      "test AUC:  0.884586764123986\n",
      "Waiting for  3 best AUC is  0.8866270807157306\n",
      "strating epoch : 48\n",
      "Train Loss:  0.1500744345676468\n",
      "Train AUC:  0.9858671406300906\n",
      "test Loss:  0.5302377790212631\n",
      "test AUC:  0.8801036374121107\n",
      "Waiting for  4 best AUC is  0.8866270807157306\n",
      "strating epoch : 49\n",
      "Train Loss:  0.14679017896393695\n",
      "Train AUC:  0.9865220976330105\n",
      "test Loss:  0.5641166716814041\n",
      "test AUC:  0.8860957675393001\n",
      "Waiting for  5 best AUC is  0.8866270807157306\n",
      "strating epoch : 50\n",
      "Train Loss:  0.14796754915312113\n",
      "Train AUC:  0.9862886891698186\n",
      "test Loss:  0.7616975158452988\n",
      "test AUC:  0.8880535914001184\n",
      "Waiting for  0 best AUC is  0.8880535914001184\n",
      "strating epoch : 51\n",
      "Train Loss:  0.15065139262791138\n",
      "Train AUC:  0.9857646643160758\n",
      "test Loss:  0.5406778566539288\n",
      "test AUC:  0.8869326065749763\n",
      "Waiting for  1 best AUC is  0.8880535914001184\n",
      "strating epoch : 52\n",
      "Train Loss:  0.14390220879072166\n",
      "Train AUC:  0.9869906218857283\n",
      "test Loss:  0.6943882256746292\n",
      "test AUC:  0.8846879838413331\n",
      "Waiting for  2 best AUC is  0.8880535914001184\n",
      "strating epoch : 53\n",
      "Train Loss:  0.14238368854465255\n",
      "Train AUC:  0.9872397997921063\n",
      "test Loss:  0.6737237796187401\n",
      "test AUC:  0.881008190923982\n",
      "Waiting for  3 best AUC is  0.8880535914001184\n",
      "strating epoch : 54\n",
      "Train Loss:  0.1456147499651794\n",
      "Train AUC:  0.9866620041656791\n",
      "test Loss:  0.6149460077285767\n",
      "test AUC:  0.8832201565793254\n",
      "Waiting for  4 best AUC is  0.8880535914001184\n",
      "strating epoch : 55\n",
      "Train Loss:  0.14236077639352845\n",
      "Train AUC:  0.9872015304871689\n",
      "test Loss:  0.6443550810217857\n",
      "test AUC:  0.8843829672542634\n",
      "Waiting for  5 best AUC is  0.8880535914001184\n",
      "strating epoch : 56\n",
      "Train Loss:  0.13819943359458303\n",
      "Train AUC:  0.9879302301190609\n",
      "test Loss:  0.686389222741127\n",
      "test AUC:  0.8882562517690654\n",
      "Waiting for  0 best AUC is  0.8882562517690654\n",
      "strating epoch : 57\n",
      "Train Loss:  0.14179445004247757\n",
      "Train AUC:  0.987317113444224\n",
      "test Loss:  0.7174247577786446\n",
      "test AUC:  0.8879548281720919\n",
      "Waiting for  1 best AUC is  0.8882562517690654\n",
      "strating epoch : 58\n",
      "Train Loss:  0.138379050306527\n",
      "Train AUC:  0.9879014090759526\n",
      "test Loss:  0.5839937552809715\n",
      "test AUC:  0.8883707649880712\n",
      "Waiting for  0 best AUC is  0.8883707649880712\n",
      "strating epoch : 59\n",
      "Train Loss:  0.1395368207111416\n",
      "Train AUC:  0.9876633676484821\n",
      "test Loss:  0.6818003952503204\n",
      "test AUC:  0.8881152095887922\n",
      "Waiting for  1 best AUC is  0.8883707649880712\n",
      "strating epoch : 60\n",
      "Train Loss:  0.1324617200228105\n",
      "Train AUC:  0.9889109055628016\n",
      "test Loss:  0.661461852490902\n",
      "test AUC:  0.8851299871545082\n",
      "Waiting for  2 best AUC is  0.8883707649880712\n",
      "strating epoch : 61\n",
      "Train Loss:  0.1379717245518443\n",
      "Train AUC:  0.9879232521289489\n",
      "test Loss:  0.6197803691029549\n",
      "test AUC:  0.8866977590810982\n",
      "Waiting for  3 best AUC is  0.8883707649880712\n",
      "strating epoch : 62\n",
      "Train Loss:  0.1340072091264897\n",
      "Train AUC:  0.9886353378487348\n",
      "test Loss:  0.6131182909011841\n",
      "test AUC:  0.8886127722496033\n",
      "Waiting for  0 best AUC is  0.8886127722496033\n",
      "strating epoch : 63\n",
      "Train Loss:  0.13920326916927314\n",
      "Train AUC:  0.9876973891440524\n",
      "test Loss:  0.5444613732397556\n",
      "test AUC:  0.8887024097695898\n",
      "Waiting for  0 best AUC is  0.8887024097695898\n",
      "strating epoch : 64\n",
      "Train Loss:  0.1308465548847095\n",
      "Train AUC:  0.989123320969955\n",
      "test Loss:  0.6375270187854767\n",
      "test AUC:  0.8875711552463355\n",
      "Waiting for  1 best AUC is  0.8887024097695898\n",
      "strating epoch : 65\n",
      "Train Loss:  0.13242621962205472\n",
      "Train AUC:  0.988902351367912\n",
      "test Loss:  0.6606975719332695\n",
      "test AUC:  0.8871075116103195\n",
      "Waiting for  2 best AUC is  0.8887024097695898\n",
      "strating epoch : 66\n",
      "Train Loss:  0.13030531966542624\n",
      "Train AUC:  0.9892865234501925\n",
      "test Loss:  0.6430408135056496\n",
      "test AUC:  0.891580392964297\n",
      "Waiting for  0 best AUC is  0.891580392964297\n",
      "strating epoch : 67\n",
      "Train Loss:  0.1285841092467308\n",
      "Train AUC:  0.9894903532801647\n",
      "test Loss:  0.6760788634419441\n",
      "test AUC:  0.882962039840572\n",
      "Waiting for  1 best AUC is  0.891580392964297\n",
      "strating epoch : 68\n",
      "Train Loss:  0.13717204520860352\n",
      "Train AUC:  0.9880253245330072\n",
      "test Loss:  0.6965259313583374\n",
      "test AUC:  0.8893542818997944\n",
      "Waiting for  2 best AUC is  0.891580392964297\n",
      "strating epoch : 69\n",
      "Train Loss:  0.1253541993448533\n",
      "Train AUC:  0.9899967345354079\n",
      "test Loss:  0.7191855013370514\n",
      "test AUC:  0.8896129547188284\n",
      "Waiting for  3 best AUC is  0.891580392964297\n",
      "strating epoch : 70\n",
      "Train Loss:  0.12598402914871654\n",
      "Train AUC:  0.9899221364314265\n",
      "test Loss:  0.6095751002430916\n",
      "test AUC:  0.8897758937303548\n",
      "Waiting for  4 best AUC is  0.891580392964297\n",
      "strating epoch : 71\n",
      "Train Loss:  0.12749924815921898\n",
      "Train AUC:  0.9896491704763832\n",
      "test Loss:  0.7108233869075775\n",
      "test AUC:  0.8874174917287833\n",
      "Waiting for  5 best AUC is  0.891580392964297\n",
      "strating epoch : 72\n",
      "Train Loss:  0.12490756055676794\n",
      "Train AUC:  0.990071452784965\n",
      "test Loss:  0.6223445013165474\n",
      "test AUC:  0.8895236336216279\n",
      "Waiting for  6 best AUC is  0.891580392964297\n",
      "strating epoch : 73\n",
      "Train Loss:  0.12454000725803605\n",
      "Train AUC:  0.9902029462668686\n",
      "test Loss:  0.6386402770876884\n",
      "test AUC:  0.8911642501926584\n",
      "Waiting for  7 best AUC is  0.891580392964297\n",
      "strating epoch : 74\n",
      "Train Loss:  0.12276390562933612\n",
      "Train AUC:  0.9904189404200429\n",
      "test Loss:  0.6553909406065941\n",
      "test AUC:  0.8940002596239598\n",
      "Waiting for  0 best AUC is  0.8940002596239598\n",
      "strating epoch : 75\n",
      "Train Loss:  0.12321501386811934\n",
      "Train AUC:  0.9903078380571035\n",
      "test Loss:  0.6325229108333588\n",
      "test AUC:  0.890414116617307\n",
      "Waiting for  1 best AUC is  0.8940002596239598\n",
      "strating epoch : 76\n",
      "Train Loss:  0.12122847983636052\n",
      "Train AUC:  0.9906632100946795\n",
      "test Loss:  0.670843280851841\n",
      "test AUC:  0.8921354434666467\n",
      "Waiting for  2 best AUC is  0.8940002596239598\n",
      "strating epoch : 77\n",
      "Train Loss:  0.1206441185021975\n",
      "Train AUC:  0.9906982384336451\n",
      "test Loss:  0.6486792415380478\n",
      "test AUC:  0.8923534325536331\n",
      "Waiting for  3 best AUC is  0.8940002596239598\n",
      "strating epoch : 78\n",
      "Train Loss:  0.11804188599428499\n",
      "Train AUC:  0.9911117933240332\n",
      "test Loss:  0.7477249726653099\n",
      "test AUC:  0.8939912069365626\n",
      "Waiting for  4 best AUC is  0.8940002596239598\n",
      "strating epoch : 79\n",
      "Train Loss:  0.11910383313535208\n",
      "Train AUC:  0.9910068485836592\n",
      "test Loss:  0.6058174818754196\n",
      "test AUC:  0.8945304587675049\n",
      "Waiting for  0 best AUC is  0.8945304587675049\n",
      "strating epoch : 80\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./\"\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "best_auc = 0\n",
    "wait = 0\n",
    "for ep in range(1,num_epochs+1):\n",
    "    print(\"strating epoch :\",ep)\n",
    "    train_df = train_df.sample(frac=1,replace=False)\n",
    "    labels_train = []\n",
    "    predictions = []\n",
    "    loss_train =[]\n",
    "    for inds in range(int(bsz/bs)):\n",
    "        nodes_u = torch.tensor(np.array(train_df[\"src\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "        nodes_v = torch.tensor(np.array(train_df[\"dst\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "        labels = torch.tensor(np.array(train_df[\"labels\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "\n",
    "        scores = model(nodes_u,nodes_v)\n",
    "        labels = labels.type_as(scores)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        labels_train.extend(list(labels.cpu().numpy()))\n",
    "        predictions.extend(list(torch.sigmoid(scores).squeeze().detach().cpu().numpy()))\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(scores.squeeze(),torch.tensor(labels).squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        loss_train.append(loss.item())\n",
    "    print(\"Train Loss: \",np.mean(loss_train))\n",
    "    print(\"Train AUC: \",roc_auc_score(labels_train,predictions))\n",
    "    labels_test = []\n",
    "    predictions = []\n",
    "    loss_test =[]\n",
    "    \n",
    "    for inds in range(int(test_bsz/bs)):\n",
    "        nodes_u = torch.tensor(np.array(test_df[\"src\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "        nodes_v = torch.tensor(np.array(test_df[\"dst\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "        labels = torch.tensor(np.array(test_df[\"labels\"])[inds*bs:(inds+1)*bs]).to(device)\n",
    "\n",
    "        scores = model(nodes_u,nodes_v)\n",
    "        labels = labels.type_as(scores)\n",
    "        \n",
    "        labels_test.extend(list(labels.cpu().numpy()))\n",
    "        predictions.extend(list(torch.sigmoid(scores).squeeze().detach().cpu().numpy()))\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(scores.squeeze(),torch.tensor(labels).squeeze())\n",
    "        \n",
    "        loss_test.append(loss.item())\n",
    "    test_auc = roc_auc_score(labels_test,predictions)\n",
    "    print(\"test Loss: \",np.mean(loss_test))\n",
    "    print(\"test AUC: \",roc_auc_score(labels_test,predictions))\n",
    "    \n",
    "    if test_auc > best_auc:\n",
    "        best_auc = test_auc\n",
    "        torch.save(model.state_dict(), save_path+\"best_auc_model_4.prm\")\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait+=1\n",
    "    print(\"Waiting for \",wait, \"best AUC is \",best_auc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
